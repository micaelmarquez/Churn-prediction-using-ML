# Churn-prediction-using-ML

This project was conducted under the guidance of an experienced Data Scientist as part of the Data Science and Machine Learning Algorithms course offered by FaMAF, National University of CÃ³rdoba. The main objective was to investigate the feasibility of utilizing machine learning techniques to predict potential churn based on specific parameters. This comprehensive endeavor encompassed various stages integral to the role of a Data Scientist, including the following activities:

- Familiarize with the data: Understand the structure, format, and meaning of the data. Gain insights into the variables, their types, and potential relationships.
- Data visualization: Visualize the data using charts, graphs, and plots to identify patterns, trends, outliers, and potential issues. This helps in gaining a deeper understanding of the data.
- Data cleaning: Identify and handle missing values, outliers, duplicates, and inconsistencies in the dataset. This step ensures data quality and integrity for accurate analysis.
- Data preprocessing: Prepare the data for analysis by transforming, normalizing, and scaling it as required. This may involve feature selection, dimensionality reduction, and handling categorical variables.
- Exploratory data analysis (EDA): Perform statistical analysis and exploratory techniques to uncover insights, understand distributions, relationships, and dependencies among variables.
- Feature engineering: Create new features or transform existing ones to improve the predictive power of the data. This can involve feature extraction, aggregation, or transformation based on domain knowledge.
- Model building and evaluation: Select appropriate machine learning algorithms, train models on the data, and evaluate their performance using suitable evaluation metrics. This step helps in building predictive models for solving specific problems.
- Model interpretation: Understand and interpret the model's results to gain insights into the underlying patterns and relationships in the data.
- Iterative refinement: Continuously iterate and refine the data analysis process by revisiting previous steps based on insights gained and feedback received.



Databases:
https://drive.google.com/file/d/1e5kjtL5308mSBI3r6D99f6WroWHmJUUt/view?usp=drive_link (for the Find "Correlations and first ML models" and for the "Churn prediction model files")
https://drive.google.com/file/d/18xjCOOazTR7b3geZ3eHe7sgx-1_H5GdM/view?usp=sharing (for the "Data Processing" file)
